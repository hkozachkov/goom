{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# goom tests\n",
    "Use this notebook to run pytest from the repo root with the `goom_jax` conda env active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "\n",
    "import goom.goom as goom\n",
    "import goom.lmme as lmme\n",
    "import goom.operations as oprs\n",
    "import goom.utils as utils\n",
    "import goom.lle as lle\n",
    "\n",
    "config = goom.config  # grab the config object from the goom module\n",
    "\n",
    "config.keep_logs_finite = True          # log(0) will return a finite floor\n",
    "config.cast_all_logs_to_complex = True  # GOOMs are complex-typed\n",
    "config.float_dtype = jnp.float32        # real dtype\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d9513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Make a chain of matrices: shape (T, N, N) ------------------------\n",
    "T, N = 10_000, 20\n",
    "key = jax.random.PRNGKey(0)\n",
    "mats = 20*jax.random.normal(key, (T, N, N), dtype=config.float_dtype)/(jnp.sqrt(N))\n",
    "\n",
    "\n",
    "# --- 1. Parallel product over *float* tensors (usually blows up) ------\n",
    "def matmul_op(a, b):\n",
    "    # a, b: (..., N, N)\n",
    "    return a @ b\n",
    "\n",
    "# lax.associative_scan does a parallel prefix of an associative op\n",
    "float_prefix_products = lax.associative_scan(matmul_op, mats, axis=0)\n",
    "\n",
    "# Final product of the whole chain:\n",
    "float_prod = float_prefix_products[-1]\n",
    "\n",
    "print(\"Computes over float tensors?\",\n",
    "      bool(jnp.isfinite(float_prod).all()))\n",
    "\n",
    "\n",
    "# --- 2. Parallel product over GOOMs -----------------------------------\n",
    "# Turn each matrix into its GOOM \"log\" representation\n",
    "log_mats = goom.to_goom(mats)   # shape (T, N, N), complex dtype\n",
    "\n",
    "\n",
    "# Parallel scan with the GOOM matmul log kernel\n",
    "log_prefix_products = lax.associative_scan(lmme.log_matmul_exp, log_mats, axis=0)\n",
    "\n",
    "# Final log-product of the whole chain in GOOM space:\n",
    "log_prod = log_prefix_products[-1]\n",
    "\n",
    "# Map back from GOOMs to (approximate) real-space product\n",
    "prod_goom = goom.from_goom(log_prod)\n",
    "\n",
    "print(\"Computes over complex GOOMs?\",\n",
    "      bool(jnp.isfinite(log_prod).all()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25447e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare LLE computed in paralle to sequential algorithm\n",
    "lle_est_par = lle.jax_estimate_lle_parallel(mats, key, dt=1.0)\n",
    "lle_est_seq = lle.jax_estimate_lle_sequential(mats, key, dt=1.0)\n",
    "lle_ratio = lle_est_par/lle_est_seq\n",
    "\n",
    "\n",
    "\n",
    "print(\"Parallel LLE vs Sequential LLE Close?:\",\n",
    "      bool(jnp.isclose(lle_ratio, 1.0, atol=1e-3, rtol=0.0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
