{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# goom tests\n",
    "Use this notebook to run pytest from the repo root with the `goom_jax` conda env active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30657710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goom module: <module 'goom' from '/oscar/home/lkozachk/code/goom/src/goom/__init__.py'>\n",
      "Python executable: /users/lkozachk/.conda/envs/jax_goom/bin/python\n",
      "Python version: 3.12.12 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 20:16:04) [GCC 11.2.0]\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import goom as goom\n",
    "\n",
    "print(\"goom module:\", goom)\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "\n",
    "import goom.lmme as lmme\n",
    "import goom.operations as oprs\n",
    "import goom.lle as lle\n",
    "\n",
    "config = goom.config  # grab the config object from the goom module\n",
    "\n",
    "config.keep_logs_finite = True          # log(0) will return a finite floor\n",
    "config.cast_all_logs_to_complex = True  # GOOMs are complex-typed\n",
    "config.float_dtype = jnp.float32        # real dtype\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00882e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CudaDevice(id=0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1128 18:35:09.739974  418464 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML library doesn't have required functions.\n",
      "W1128 18:35:09.746421  236058 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML library doesn't have required functions.\n"
     ]
    }
   ],
   "source": [
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b8d9513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computes over float tensors? False\n",
      "Computes over complex GOOMs? True\n"
     ]
    }
   ],
   "source": [
    "# --- Make a chain of matrices: shape (T, N, N) ------------------------\n",
    "T, N = 10_000, 20\n",
    "key = jax.random.PRNGKey(0)\n",
    "mats = 20*jax.random.normal(key, (T, N, N), dtype=config.float_dtype)/(jnp.sqrt(N))\n",
    "\n",
    "\n",
    "# --- 1. Parallel product over *float* tensors (usually blows up) ------\n",
    "def matmul_op(a, b):\n",
    "    # a, b: (..., N, N)\n",
    "    return a @ b\n",
    "\n",
    "# lax.associative_scan does a parallel prefix of an associative op\n",
    "float_prefix_products = lax.associative_scan(matmul_op, mats, axis=0)\n",
    "\n",
    "# Final product of the whole chain:\n",
    "float_prod = float_prefix_products[-1]\n",
    "\n",
    "print(\"Computes over float tensors?\",\n",
    "      bool(jnp.isfinite(float_prod).all()))\n",
    "\n",
    "\n",
    "# --- 2. Parallel product over GOOMs -----------------------------------\n",
    "# Turn each matrix into its GOOM \"log\" representation\n",
    "log_mats = goom.goom.to_goom(mats)   # shape (T, N, N), complex dtype\n",
    "\n",
    "\n",
    "# Parallel scan with the GOOM matmul log kernel\n",
    "log_prefix_products = lax.associative_scan(lmme.log_matmul_exp, log_mats, axis=0)\n",
    "\n",
    "# Final log-product of the whole chain in GOOM space:\n",
    "log_prod = log_prefix_products[-1]\n",
    "\n",
    "# Map back from GOOMs to (approximate) real-space product\n",
    "prod_goom = goom.goom.from_goom(log_prod)\n",
    "\n",
    "print(\"Computes over complex GOOMs?\",\n",
    "      bool(jnp.isfinite(log_prod).all()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25447e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel LLE vs Sequential LLE Close?: True\n"
     ]
    }
   ],
   "source": [
    "# compare LLE computed in paralle to sequential algorithm\n",
    "lle_est_par = lle.jax_estimate_lle_parallel(mats, key, dt=1.0)\n",
    "lle_est_seq = lle.jax_estimate_lle_sequential(mats, key, dt=1.0)\n",
    "\n",
    "print(\"Parallel LLE vs Sequential LLE Close?:\",\n",
    "      bool(jnp.isclose(lle_est_par, lle_est_seq, atol=1e-3, rtol=1e-3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba5f2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dt = 1e-3  # time step\n",
    "\n",
    "\n",
    "def lorenz(x, sigma=10.0, rho=28.0, beta=8.0 / 3.0):\n",
    "    \"\"\"Lorenz vector field: dx/dt = f(x).\"\"\"\n",
    "    x_, y_, z_ = x\n",
    "    dx = sigma * (y_ - x_)\n",
    "    dy = x_ * (rho - z_) - y_\n",
    "    dz = x_ * y_ - beta * z_\n",
    "    return jnp.array([dx, dy, dz])\n",
    "\n",
    "\n",
    "def euler_step(x, dt=dt, sigma=10.0, rho=28.0, beta=8.0 / 3.0):\n",
    "    \"\"\"One Euler step for the Lorenz system: x_{n+1} = x_n + dt * f(x_n).\"\"\"\n",
    "    return x + dt * lorenz(x, sigma=sigma, rho=rho, beta=beta)\n",
    "\n",
    "\n",
    "def simulate_lorenz_with_jacobians(\n",
    "    x0,\n",
    "    T,\n",
    "    dt=dt,\n",
    "    sigma=10.0,\n",
    "    rho=28.0,\n",
    "    beta=8.0 / 3.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulate T steps of Lorenz and return states and Jacobians.\n",
    "\n",
    "    Args:\n",
    "        x0: shape (3,) initial state.\n",
    "        T:  number of time steps (int).\n",
    "        dt, sigma, rho, beta: integration and Lorenz parameters.\n",
    "\n",
    "    Returns:\n",
    "        states:    shape (T+1, 3), states from t=0..T\n",
    "        jacobians: shape (T, 3, 3), J_t = d x_{t+1} / d x_t, for t=0..T-1\n",
    "    \"\"\"\n",
    "\n",
    "    def step_with_jac(x, _):\n",
    "        # Define a pure function for the step map so we can differentiate it\n",
    "        def step_fn(x_):\n",
    "            return euler_step(x_, dt=dt, sigma=sigma, rho=rho, beta=beta)\n",
    "\n",
    "        x_next = step_fn(x)\n",
    "        J = jax.jacrev(step_fn)(x)  # 3x3 Jacobian of step map at x\n",
    "        return x_next, (x_next, J)\n",
    "\n",
    "    # lax.scan carries the state and accumulates (state, J)\n",
    "    xT, (xs, Js) = lax.scan(step_with_jac, x0, xs=None, length=T)\n",
    "\n",
    "    # Prepend the initial state to get states of length T+1\n",
    "    states = jnp.vstack([x0[None, :], xs])\n",
    "\n",
    "    return states, Js\n",
    "\n",
    "\n",
    "# Optionally JIT-compile for speed (T is static)\n",
    "simulate_lorenz_with_jacobians_jit = jax.jit(\n",
    "    simulate_lorenz_with_jacobians,\n",
    "    static_argnames=(\"T\",)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a899181",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = jnp.array([1.0, 0.0, 1.0])\n",
    "T = 400_000  # simulate 400K\n",
    "key = jax.random.PRNGKey(42)\n",
    "\n",
    "states, jac_vals = simulate_lorenz_with_jacobians_jit(x0, T)\n",
    "\n",
    "# not giving the correct answers\n",
    "lle_est_par = lle.jax_estimate_lle_parallel(jac_vals, key, dt=dt)\n",
    "lle_est_seq = lle.jax_estimate_lle_sequential(jac_vals, key, dt=dt)\n",
    "\n",
    "# print(f\"{lle_est_par:.4f}\")\n",
    "# print(f\"{lle_est_seq:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2beb7bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel LLE: 0.8978  | time = 0.1390 s\n",
      "Sequential LLE: 0.8951 | time = 3.7668 s\n",
      "Speedup (seq / par): 27.10x\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "x0 = jnp.array([1.0, 0.0, 1.0])\n",
    "T = 400_000\n",
    "key = jax.random.PRNGKey(42)\n",
    "\n",
    "# Warmup simulate (if it's jitted)\n",
    "states, jac_vals = simulate_lorenz_with_jacobians_jit(x0, T)\n",
    "\n",
    "# Warmup LLE fns (compile them)\n",
    "_ = lle.jax_estimate_lle_parallel(jac_vals, key, dt=dt)\n",
    "_ = lle.jax_estimate_lle_sequential(jac_vals, key, dt=dt)\n",
    "\n",
    "def benchmark(f, *args, n_runs=5, **kwargs):\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        start = time.perf_counter()\n",
    "        out = f(*args, **kwargs)\n",
    "        # Make sure the computation actually finishes on the device\n",
    "        out = jax.block_until_ready(out)\n",
    "        end = time.perf_counter()\n",
    "        times.append(end - start)\n",
    "    return min(times), out  # return best time and last result\n",
    "\n",
    "# If your functions use randomness, *split* the key so they each get their own\n",
    "key_base = jax.random.PRNGKey(42)\n",
    "key_par, key_seq = jax.random.split(key_base)\n",
    "\n",
    "t_par, lle_est_par = benchmark(\n",
    "    lle.jax_estimate_lle_parallel,\n",
    "    jac_vals,\n",
    "    key_par,\n",
    "    dt=dt,\n",
    ")\n",
    "\n",
    "t_seq, lle_est_seq = benchmark(\n",
    "    lle.jax_estimate_lle_sequential,\n",
    "    jac_vals,\n",
    "    key_seq,\n",
    "    dt=dt,\n",
    ")\n",
    "\n",
    "print(f\"Parallel LLE: {float(lle_est_par):.4f}  | time = {t_par:.4f} s\")\n",
    "print(f\"Sequential LLE: {float(lle_est_seq):.4f} | time = {t_seq:.4f} s\")\n",
    "print(f\"Speedup (seq / par): {t_seq / t_par:.2f}x\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
